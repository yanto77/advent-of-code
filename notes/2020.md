# Advent Of Code 2020, notes

# Overview

Day 01 = 189 μs
Day 02 = 572 μs
Day 03 =  62 μs
Day 04 = 377 μs
Day 05 =  19 μs
Total:  1220 μs

References:
* https://www.reddit.com/r/adventofcode/wiki/solution_megathreads
* https://github.com/zedrdave/advent_of_code, Python, posts notes/comments
* https://github.com/DarthGandalf/advent-of-code, creates visualizations
* https://github.com/thorstel/Advent-of-Code-2020
* https://github.com/tboschi/advent-of-code-2020
* https://github.com/Bogdanp/awesome-advent-of-code#c-2, link list
* https://www.forrestthewoods.com/blog/solving-advent-of-code-in-under-a-second/
* https://github.com/yulrizka/adventofcode#2020 (Go)

See also:
* https://github.com/Voltara/advent2017-fast
* https://github.com/Voltara/advent2018-fast
* https://github.com/Voltara/advent2019-fast
* and probably 2020 version at some point?

# Day 00

Purpose of doing these: to have fun and to learn. My expectation is that the solutions can be found relatively easily. Improving on them is what is going to take time and extensive effort. Thus, I'm looking mostly for the journey here, not the destination.

# Day 01

The initial implementation with simplest bruteforce double/triple loop takes 3100 μs [389bd82]. Next natural step would be to ask what and where we could improve it? There is the [PPC course](http://ppc.cs.aalto.fi) at Aalto, with [notes about performance debugging](http://ppc.cs.aalto.fi/2020/debug/perf/), so let's start with those.

Collecting CPU usage statistics can be done with `perf stat`:

```sh
$ perf stat $PROG $ARGS
```

What are we looking for in the statistics?
* CPUs utilized: should be close to 1 for single-threaded, and to N for multi-threaded solutions (where N is the number of available threads). A thread waiting, for e.g., memory operations or other threads, simply wastes time.
* Frontend cycles idle: "The cycles stalled in the front-end are a waste because that means that the Front-End does not feed the Back End with micro-operations. This can mean that you have misses in the Instruction cache, or complex instructions that are not already decoded in the micro-op cache. Just-in-time compiled code usually expresses this behavior." [[ref]](https://stackoverflow.com/a/29059380)
* Backend cycles idle: "The cycles stalled in the back-end are a waste because the CPU has to wait for resources (usually memory) or to finish long latency instructions (e.g. transcedentals - sqrt, reciprocals, divisions, etc.)." [[ref]](https://stackoverflow.com/a/29059380)
* Instructions per cycle: more than 1.0 can be considered good [[1]](http://www.brendangregg.com/perf.html#CPUstatistics), [[2]](http://ppc.cs.aalto.fi/2020/debug/perf/).
* Branch misses: "If a conditional branch usually goes a specific way, the next time it appears, the predictor will assume it will take the same route.". Therefore, sorting input so that there are less randomness with branching outcomes is better. [[ref]](https://www.linux.com/training-tutorials/performance-analysis-linux/)

If there are "not counted" entries, the reason for that may be that the program in question executes for a very short amount of time. The percentage in the parenthesis tells that this counter was counted only for that amount of running time. Splitting the counters into multiple runs seems to help this issue. [[ref]](https://stackoverflow.com/a/37607099)

Collecting events can be done with `perf record && perf report`:

```sh
$ perf record $PROG $ARGS
$ perf report
```

Using default sampling frequency may not be enough. For example, default frequency of 4000 Hz  will result in resolution of 250 μs. Based on [example results from another year](https://github.com/Voltara/advent2018-fast) such resolution would return only 1-2 events for more than half of the solutions. It is possible to increase the frequency to greater values, e.g. 63500 Hz, with `perf record --freq=max`. Such frequency gives resolution of ~15.7 μs, which should be enough.

## Improvements

Sorting input vector is the first thing that can be done, as suggested by [[ref]](https://www.linux.com/training-tutorials/performance-analysis-linux/). The execution time drops to 200 μs. This operation reduces the number of branch misses, which in turn means that the branch predictor is able to keep backend filled with operations. The absolute number of cycles and the ones that stall is reduced by ~70-80%, however, the relative to each other these values are still in range 30-40%.


Some references:
* https://www.agner.org/optimize/optimizing_cpp.pdf



# Day 02

Parsing previous thing was relatively easy. But now we actually have something relatively complex to parse.
- One way would be to implement yourself an algorithm that checks input char by char
    -> ad hoc variant, could also implement checking while reading? we are only counting, so copying the data wouldn't be necessary.
    -> if string_view's are used, then no copies should be made.
- Another option is to use regex?
    -> ctre seems fast. is it fast enough?
- Anything else?

Base solution seems to take approx 600 μs.

# Day 03

Base solution takes approx. 60 μs. There isn't really any point to optimize that.

As an exercise, there is the constant input data which we would need to analyze with different parameters. As is, it sounds like a perfect setup for multithreading, right? Maybe, but multiple threads or processes have their own management overhead, so when would it be reasonable to share this task?

* Adding simple "#pragma omp parallel for" to process each slope separately makes the final time be approx 1300 μs. Sometimes though the runtime jumps up to as high as 7000 μs, and probably even higher in some situations. Therefore, we should consider adding multithreading next time when the runtime is more than 10 ms.

# Day 04

* switch by key found in input. assumption: comparing strings (and string_views) is complex, but if they are hashed, comparison should be faster.

* initial solution (for part1) takes 350 μs, for both parts (with input validation): 420 μs

* by default, `passport_t` looks as follows. what if instead of using full types, we could use our knowledge of limits of our input data and reduce the size of this class? test it out with uint8/16_t instead of ints.

```cpp
    // State
    uint8_t m_filled = 0;
    uint8_t m_valid = 0;

    // Data
    int m_byr;                  => uint16_t m_byr;
    std::string_view m_cid;
    EyeColor m_ecl;
    int m_eyr;                  => uint16_t m_eyr;
    int m_hcl;
    std::pair<int, bool> m_hgt; => std::pair<uint8_t, bool> m_hgt;
    int m_iyr;                  => uint16_t m_iyr;
    int m_pid;                  => uint32_t m_pid;
```

by doing that:
* 56 bytes -> 40 bytes. In total, there are 290 passports, so total memory size has been reduced by 4640 bytes. Not a big issue with these data sizes.
* `perf stat` output hasn't really changed much.

maybe some gains could be noticed by optimizing away until 32 bytes are met and aligning allocated memory?

* hashing these small strings also didn't help, but instead increased the runtime to 4000-5000 μs.

# Day 05

Interesting technique is to add static_assert checks. Easier to construct the initial line conversion, when there are some example inputs and outputs for a method. Iteration speed is also great, as there's no need to run additional command -- the compile command both compiles and "runs" the code.

> Here are some other boarding passes:
>
>    BFFFBBFRRR: row 70, column 7, seat ID 567.
>    FFFBBBFRRR: row 14, column 7, seat ID 119.
>    BBFFBBFRLL: row 102, column 4, seat ID 820.

Which then converts to:

```cpp
constexpr std::pair<uint8_t, uint8_t> convert_line(const std::string_view& view)
{
    ...
}

static_assert(convert_line("BFFFBBFRRR") == std::pair<uint8_t, uint8_t>{0, 0});
static_assert(convert_line("FFFBBBFRRR") == std::pair<uint8_t, uint8_t>{1, 0});
static_assert(convert_line("BBFFBBFRLL") == std::pair<uint8_t, uint8_t>{0, 1});
```

Otherwise, the input is a key to the binary tree, which just needs to be translated.

Initial solution to both parts takes 21 μs. The major factor here is probably that the data is static and has size of 1024 entries (128 rows by 8 columns). As such, there isn't really any need to optimize, as the return on invested effort will be minuscule.

Later, found out [this solution](https://github.com/tboschi/advent-of-code-2020/blob/master/day05/cpp/src/part2.cpp). Couple of notes:

* It didn't occur to me that we were evaluating one single binary tree, not two... That simplifies things a bit.
    -> Although, most probably it simplifies only the code, not the actual implementation. As the entries are already in contiguous 2-dimensional array, so we can make it 1-dimensional, but the memory layout is still the same.

* After trying that solution in my project, it showed that execution is now approx 150 μs, which is magnitude larger than initial solution. Why is that? Couple of guesses:
    * Is it the additional sorting?
        -> Removing sorting (when saving indice numbers) yields wrong results, but the execution time itself drops to 90 μs.
    * Initial solution worked on an array of booleans, where the index marked the seat id. In their solution, they stored size_t indices directly. Is it the additional memory which affects the cache lines etc?
        * each std::vector has 24 byte overhead.
        *
            ```
            // Each array is initialized with 1024 elements.
            std::vector<uint16_t>   v1;
            std::vector<size_t>     v2;
            std::array<bool, 1024>  v3;

            sizeof(bool)        => 1
            sizeof(uint16_t)    => 2
            sizeof(size_t)      => 8

            sizeof(v3)  => 1024
            sizeof(sizeof(v1) + sizeof(uint16_t) * v1.capacity()) => 2072
            sizeof(sizeof(v2) + sizeof(size_t) * v2.capacity()) => 8216
            ```
        * going back to array<bool> didn't get us close to initial solutions performance. with sorting removing, measurements that resulted in values above 100 μs were noticeable somtimes. with this array change, it seems that it doesn't happen as often, so i would guess that changing this had some effect. but, as noticed with previous days, memory doesn't really seem to be the issue here.

    * Is it the unification of `if (sv[i] == 'B' || sv[i] == 'R')` part into one?
        * That was the main thing! This is understandable, because in the inner loop, we evaluate first part of the if-clause for 7 times and then throw away the result. The same goes for the second part, where it depends on the input. Let's assume that input is uniformly distributed, thus the second part is evaluated and thrown away for 7/2 = 3 times.

        Given 10 chars:
            7 chars
                -> 3.5 succeed on first if, second if not evaluated
                -> 3.5 fail on first if, and evaluate 2nd if unnecessarily
            3 chars
                -> evaluates first if 3 times, all are unnecessary
                -> evaluation of 2nd if is always necessary
            In total: 3.5 + 3 unnecessary if evaluations. We only need 10 though, so 16.5 is too much. Strange that reducing number of possible ifs by ~40% reduces the solution's time from 90 μs to 20-25 μs (~75%). So maybe there's some compiler optimizations also going in the background? Or maybe it's the branch predictor being reset affecting the result so much?

        -> checking the results with `perf stat -r 1000` shows that on average separating if-clauses helps by reducing branch-misses and stalled-cycles-backend metrics. also IPC increases from 1.30 to 1.37. so, definetly the branch predictor like the version with separated if-clauses better.

# Day 07

* Purpose of hashing string?
    * We are comparing longer strings made of two parts. So, comparing just first part would require comparing only couple of characters. But with second part, some comparisons will require much more time, as they will need to evaluate ~10 chars to only reach the part that matters.

* When having a matrix, there will be bunch of empty space.
    * Spend some time to compact? Would help at least initial state.
    * The lines that have only one value -> they are ending point, they only have themselves. So push them in the end.

* The first task that I've got stuck in. Mostly with parsing the input into usable format.

* Others results:
    * [thorstel's solution](https://github.com/thorstel/Advent-of-Code-2020/blob/master/day07/main.cc) gives 4500-5000 us.

* Or don't use matrix at all. There isn't really that many node connections, so there's bunch of empty space. 
    * From the code organization perspective, it also adds complexity, because we would need to track non-connections as well and handle them. The total lines of code were around 250 (excl tests), which (imo) goes from "more or less understanble" to "less understanble".
    * The current way of doing yielded approx. similar timings of 4500-5000 us. It tells that the additional complexity is not really worth it.

* base case, approx 3700 us:
    - with graph parsed into vector of <from, to, cost> rules/links.
    - with from/to indexes saved as std::string_view's.

* key translation:
    - instead of saving indexes as string_view, translate them with unordered_map and running index into size_t's.
    - this results in runtime of approx 2500 us.

* otherwise, based on `perf record`, 
    - about 30-40% is spent in ctre methods.
    - about 5% + 5% is spent in the main part1-part2 related methods, working on the parsed data.

## Day 08

Interesting question/problem.

* My initial solution was to add extra boolean field to parsed instruction struct, to check when the program starts executing the already executed instructions. Afterwards, checking others solutions, found [TartanLlama's solutions](https://github.com/TartanLlama/advent-of-code-2020). The actual implementation of translating the program into assembly is way out of my understanding at the moment. The idea to overwrite the instruction, however, seems like something I could try.
    * Results are:
        - with `bool visited`, approx 500-510 us
        - with overwriting instruction type, approx 420-430 us.
    * Writing the bool or additional if-clause, is not the cause behind the performance drop. Only when the boolean is removed from the op_t struct, the performance increases. So it seems that the issue is that we are getting too much unnecessary data (with boolean being there). And that is very clear when we check the struct sizes:
        
        ```cpp
        enum op_type_t_1: { ERR };
            // -> size: 4
        enum op_type_t_2: uint8_t { ERR };
            // -> size: 1
        struct op_t_1 { op_type_t_1 type; int arg1; };
            // -> size: 8 = 4 + 4
        struct op_t_2 { op_type_t_1 type; int arg1; bool visited; };
            // -> size: 12 = 4 + 4 + 1 + (3)
        struct op_t_3 { op_type_t_2 type; int16_t arg1; };
            // -> size: 4 = 1 + 2 + (1)
        struct op_t_4 { op_type_t_2 type; bool visited; int16_t arg1; };
            // -> size: 4 = 1 + 1 + 2
        ```

    * max `arg1` is 576, signed! hence we can use int16_t for `arg1`. as such, we could also pack the `bool` inside, without extra cost.
        -> however, decreasing struct to 4 bytes, as opposed to 8 bytes, doesn't achieve any major change in the performance.
        -> could it be because the allocation is not properly aligned to memory, so we are in any case retrieving 8 byte chunks?
            -> TODO: how to align?

* bruteforce solutions: fast already, the input is small

* the execution logic could be made into a graph, see image. would there be more fancier algorith?

## Day 09

Small input size, let's bruteforce this. Initial submission takes approx 500 us. With the actual solution we need to be careful to use long ints, because:
* max for int32: 2147483647
* max for int64: 9223372036854775807
* max for input: 70344731032752

## Day 10

* 'The fastest algorithm can frequently be replaced by one that is almost as fast and much easier to understand.' -- Douglas W. Jones [[ref]](https://twitter.com/CompSciFact/status/1341560415990538241)

* stuck to get it working for the second test input:
    * https://www.youtube.com/watch?t=380&v=cE88K2kFZn0&feature=youtu.be [1]
        * memoization -> evaluate paths and save the result
    * https://www.youtube.com/watch?v=KzTBz--x47E&feature=youtu.be [2]
        * consecutive numbers are important -> count groups "as is", don't process them.
            * doing sliding window on them, e.g. processing "abcd" as "ab"+"cd" or "abc"+"bcd", yielded either too many or too little variants
            * doing tribonacci was actually correct, keyed by the lengths of substrings of "1"s.
                -> there are no 2-diffs, so doesn't need to handle those
        * http://www.maurits.vdschee.nl/scatterplot/ shows scatter plots for top100 solution times -> shows the hard problems clearly

* doing it as [2] showed, yields a solution which executes in 10us. wow.

## Day 11

* Initial solution approx 7700 μs. Padding used to reduce if-fing inside inner loop.
* This is very similar to some task in the PPC course, can't remember which one though.

* While preparing for 2nd part, I've extracted the part that calculates nearest occupied seats for a cell into own method. That in itself, with no other changes, resulted in 1800 us reduction in runtime. Why would that happen?

    * One thing we can do here, is to investigate the assembly output, as taught in the PPC course. It can be generated by specifying extra flags to the compiler. Good thing is the Cmake actually generates these targets (by default?), so the only thing we would need to do is to:
        ```
        cd build && make src/day11.s
        ```
    , which would generate the file in `CMakeFiles/advent2020.dir/src/day11.cpp.s`

    The output is huge, so to find out the relevants parts, we can add "asm("### indicator");" to the code and search for those indicators in the asm output.

    * From the assembly output, we can see that there initial instructions are slightly different. The follow-up seems mostly same.

    The registers used by:
        * "own method":
            * edi,
            * rax, r8, r9, rbp, rbx, rcx, rdi, rdx, rip, rsi, rsp,
            * xmm0, xmm1, ymm0, ymm1.
        * inline:
            * eax, ebx, edi.
            * r8, r9, r10, r15, rbp, rbx, rcx, rdi, rdx, rip, rsi, rsp.
            * xmm0, xmm1, ymm0, ymm1.

    | instr | inline | own method | notes |
    |-|-|-|-|
    | leaq | 4 | 4 | asd |
    | movq | 4 | 4 | asd |
    | movzwl | 1 | 0 | asd |
    | movzbl | 0 | 1 | asd |
    | vmovd | 2 | 1 | asd |
    | vpand | 1 | 1 | asd |
    | vpcmpeqb | 1 | 1 | asd |
    | vpextrb | 2 | 0 | asd |
    | vpinsrb | 7 | 7 | asd |
    | vpmovsxbq | 1 | 1 | asd |
    | vpmovzxbq | 1 | 1 | asd |
    | vpshufd | 1 | 1 | asd |

    So, assuming that I haven't misunderstood anything, it would seem that with inline method the compiler must organize the arguments in the memory to work with pre-existing data. While, with extracted method, the compiler can optimize things away??

    The main point here, however, is that I wouldn't've though that extracting a part of code into own method would have such big effect on the runtime (7700 us -> 5900 us, approx 25% reduction). Without measuring such an effect would not be noticeable. It is certainly good when it happens in direction of smaller runtime, but what if such change would happen the other way around? It would seem that in performance critical applications, there should be a performance tests running all the time to catch possible regressions of this type.

    * Also, noted that the debug information outputted with RelWithDebInfo actually affects the runtimes. With Release config, the runtime (of all solutions so far) is approx 9500 us, while with RelWithDebInfo it stays around 10500 us.

* Part2:
    * evaluating 3x3 window is already quite bad w.r.t. to the cache access. evaluating part2 is much worse and it can be seen from the initial submission time: approx 40000 us.

    * checking some solutions from reddit's megathread:
        * use two separate arrays for seats/floors and for the free/taken seats -> will allow to use 1/0 for indication and may optimize/remove some if-clauses and counts.
        * would it be possible to calculate multiple target cells at once? that is, instead of going to a cell and checking around for occupied seats, we would start from each seat and add it to all other seats it may affect.


## Day 13

    * simple bruteforce would be to evaluate each `kerroin`, and check the solution. it works fairly well on smaller inputs and when the solution is found fast. otherwise, it just takes a whole lot longer to loop.

    * instead, we can recognize that we have line equations and the answers are found at the intersections. instead of being O(forever), it is practically O(1).

    * however, how do we deal with the second part? the first part we know the end result we expect, so we directly check intersection between given buslines and wanted base-line. in part 2, we actually need to _find_ the base-line first?

    * as per Voltara's notes, what we have is not a system of linear equations, but a system of congruences.
        * they are solving this system using "modular multiplicative inverse".
        * https://www.mathemania.com/lesson/system-linear-congruences/ has some simple explanations
        * https://shoup.net/ntb/ntb-v2.pdf, chapters 1-2
        * !!> https://fasterthanli.me/series/advent-of-code-2020/part-13
            * "A piece like Advent of Code — Day 13 took five days to put together!" [https://fasterthanli.me/articles/2020-retrospective]
        * https://www.dave4math.com/mathematics/chinese-remainder-theorem/

    see also:
    * https://sites.millersville.edu/bikenaga/number-theory/systems-of-congruences/systems-of-congruences.html
    * https://www.reddit.com/r/adventofcode/comments/kc4njx/2020_day_13_solutions/ggv5a0s/?utm_source=reddit&utm_medium=web2x&context=3
        > I found out that the "Chinese remainder theorem" was involved so I used
        > the following videos to gain a grasp of how modular arithmetic and the theorem worked:
        >    https://youtu.be/5OjZWSdxlU0
        >    https://youtu.be/6dZLq77gSGU
        >    https://youtu.be/zIFehsBHB8o
        > also:
        > https://www.dcode.fr/chinese-remainder

    * https://github.com/blu3r4y/AdventOfLanguages2020/blob/main/src/day13.cpp

## Random stuff

    * question of inlining vs separate functions
        * inlining is better, because the compiler may optimize simple function calls away. however, having everything in the header is bad for the compilation times. 
        
        * one of the solutions is to use precompiled headers, reducing some cost of processing headers by doing it only once. this precompiled header will be included by every translation unit, so the compiler should have everything it needs to optimize.
            -> adding precompiled headers with cmake is a matter of single `target_precompile_headers`.
            -> comparing sample values on current variations of Days 1-12 (except 11) shows that the runtime is reduced by 500 us in total.

        * another solution would be to use LTO or thin-LTO
            * would be interesting to try. in theory, it would allow to split the headers/cpps, instead of keeping everything in the header, while still being able to optimize during linktime, as everything is seen at that point (as opposed to during compilation).

    * learning to understand `perf`
        * https://jvns.ca/blog/2014/05/13/profiling-with-perf/
        * https://www.youtube.com/watch?v=nXaxk27zwlk

## Day 14

    * initial solution takes 15-20 ms. permutations required bunch of bit flipping functions/helpers. the memory values are saved in a std::map, which should have logarithmic complexity for insertion.
        -> not sure if there would be some solution that would prevent writing the values in the first place. in the end, part1 writes 400 addresses and part2 -- 83000. maybe the memory could be reserved beforehand? std::map doesn't have a reserve() method, like std::vector would.

        * from `perf` output, nothing really pops up.
            * "0.17 stalled cycles per insn"
            * "1.38 insn per cycle", seems good enough
            * "24.14% backend cycles idle"
            * "1.97% branch misses"

        * from `perf record && report`
            * 25% is spent in std::_Rb_* methods
            * 10% is spent in malloc

    * changing std::map into std::unordered_map was a good move. runtime drops to 10 ms average, although with large range (6-11ms).
        * `perf` output shows better values
            * "0.08 stalled cycles per insn"
            * "1.75 insn per cycle"
            * "13.76% backend cycles idle"
            * "1.13% branch misses"

        * `perf record && report`
            * instead of 25% in std::map, now 12% is spent in std::_Hashtable
            * malloc still uses approx 10%.

    * other ideas:
        * https://github.com/Scrumplesplunge/aoc2020/blob/master/src/day14.c
            * this solution uses the knowledge of the two other masks to construct the `setX` when necessary. in my initial solution, i've saved all three masks. from performance point of view, it doesn't seem to make a large difference though.

            * the way the iteration of floating values was done is something that goes too much over my head at the moment. in essense, it's doing the same thing, but in fewer lines of code. there is slight improvement in performance.

        * what if we would process all data in someway, so that line-by-line parsing would not be intertwined with all this bitmask evaluation? this probably has an effect of instruction cache, reducing the misses. would this be something that would reduce "frontend-cycles-idle" metric in perf?

        * it's also unclear why the same program can run in 6307us or in 11872us. the average stays around 9-10ms, but the deviation is high. as the program doesn't change, it is not the optimization of the code itself. the thing that changes between the runs is the cache?

## Day 15

    * Base: 1.7 sec. After combining and simplifying 1.6 sec.
    * Using hashmap is probably unnecessary. Would it be possible to replace it with bunch of pre-allocated memory and skip the hashing process?