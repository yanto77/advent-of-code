# Advent Of Code 2020, notes

# Day 00

Purpose of doing these: to have fun and to learn. My expectation is that the solutions can be found relatively easily. Improving on them is what is going to take time and extensive effort. Thus, I'm looking mostly for the journey here, not the destination.

# Day 01

The initial implementation with simplest bruteforce double/triple loop takes 3100 μs [389bd82]. Next natural step would be to ask what and where we could improve it? There is the [PPC course](http://ppc.cs.aalto.fi) at Aalto, with [notes about performance debugging](http://ppc.cs.aalto.fi/2020/debug/perf/), so let's start with those.

Collecting CPU usage statistics can be done with `perf stat`:

```sh
$ perf stat $PROG $ARGS
```

What are we looking for in the statistics?
* CPUs utilized: should be close to 1 for single-threaded, and to N for multi-threaded solutions (where N is the number of available threads). A thread waiting, for e.g., memory operations or other threads, simply wastes time.
* Frontend cycles idle: "The cycles stalled in the front-end are a waste because that means that the Front-End does not feed the Back End with micro-operations. This can mean that you have misses in the Instruction cache, or complex instructions that are not already decoded in the micro-op cache. Just-in-time compiled code usually expresses this behavior." [[ref]](https://stackoverflow.com/a/29059380)
* Backend cycles idle: "The cycles stalled in the back-end are a waste because the CPU has to wait for resources (usually memory) or to finish long latency instructions (e.g. transcedentals - sqrt, reciprocals, divisions, etc.)." [[ref]](https://stackoverflow.com/a/29059380)
* Instructions per cycle: more than 1.0 can be considered good [[1]](http://www.brendangregg.com/perf.html#CPUstatistics), [[2]](http://ppc.cs.aalto.fi/2020/debug/perf/).
* Branch misses: "If a conditional branch usually goes a specific way, the next time it appears, the predictor will assume it will take the same route.". Therefore, sorting input so that there are less randomness with branching outcomes is better. [[ref]](https://www.linux.com/training-tutorials/performance-analysis-linux/)

If there are "not counted" entries, the reason for that may be that the program in question executes for a very short amount of time. The percentage in the parenthesis tells that this counter was counted only for that amount of running time. Splitting the counters into multiple runs seems to help this issue. [[ref]](https://stackoverflow.com/a/37607099)

Collecting events can be done with `perf record && perf report`:

```sh
$ perf record $PROG $ARGS
$ perf report
```

Using default sampling frequency may not be enough. For example, default frequency of 4000 Hz  will result in resolution of 250 μs. Based on [example results from another year](https://github.com/Voltara/advent2018-fast) such resolution would return only 1-2 events for more than half of the solutions. It is possible to increase the frequency to greater values, e.g. 63500 Hz, with `perf record --freq=max`. Such frequency gives resolution of ~15.7 μs, which should be enough.

## Improvements

Sorting input vector is the first thing that can be done, as suggested by [[ref]](https://www.linux.com/training-tutorials/performance-analysis-linux/). The execution time drops to 200 μs. This operation reduces the number of branch misses, which in turn means that the branch predictor is able to keep backend filled with operations. The absolute number of cycles and the ones that stall is reduced by ~70-80%, however, the relative to each other these values are still in range 30-40%.


Some references:
* https://www.agner.org/optimize/optimizing_cpp.pdf