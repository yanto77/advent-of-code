
# day 3

https://en.wikipedia.org/wiki/Multiple_line_segment_intersection


# day 4


we can return early, and not need to calculate pt2 counters.

=> base case: 14000 us
=> early return case: 4900 us


in addition, `is_valid()` seems like a good candidate for vector instructions.

    ```
    uint8_t     -> 8 bits
        6 chars => 48 bits

    64 bit stuff is MMX
    128 bit is SSE(2)
    256 bit is AVX(2)
    ```

interestingly, packing the digits to `__m64` (and using MMX instructions) instead of std::array<uint8_t, 6> actually makes things much slower. executing only part1 -- base version gives 2500 us. MMX version does generate much smaller assembly with only 15 lines, while the base version generates 42. however, MMX version runs _much_ slower -- around 6000 us.

but why such effect?
    - maybe it could be explained by the branch predictor? as we are processing the numbers in a brute-force fashion, the majority of the if-clauses are same for subsequent numbers, so the CPU guesses are rarely wrong. with vectorized instructions, we are removing some of the if-clauses, which prevents CPU from guessing forward. so, predictable if-clauses may be better than less if-clauses?

* how all the instrinsic headers differ? e.g <immintrin.h> vs <mmintrin.h> vs others?
    -> https://stackoverflow.com/questions/11228855/header-files-for-x86-simd-intrinsics


# day 6

* hashmap of (parent -> all children) seems logical. however, it feels like knowing parent of a child is more important than the other way around. maybe switching to hashmap of (child -> parent) will help?
    -> actually, part1 benefits from former, part2 benefits from latter? so, the data struct cannot be shared then?

* with hashmap of (parent -> all children):
    [timer] parse 649 μs
    [timer] get_orbit_checksum 80 μs
    [timer] get_parents 2033 μs
    [timer] get_parents 1685 μs
    [timer] get_orbit_difference 3729 μs

    NB: get_orbit_difference includes get_parents times
